<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>7_yolov3.lib.infer_detector API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>7_yolov3.lib.infer_detector</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from sys import platform

from models import * 
from utils.datasets import *
from utils.utils import *


class Infer():
    &#39;&#39;&#39;
    Class for main inference

    Args:
        verbose (int): Set verbosity levels
                        0 - Print Nothing
                        1 - Print desired details
    &#39;&#39;&#39;
    def __init__(self, verbose=1):
        self.system_dict = {};
        self.system_dict[&#34;verbose&#34;] = verbose;
        self.system_dict[&#34;local&#34;] = {};


        self.system_dict[&#34;params&#34;] = {};
        self.system_dict[&#34;params&#34;][&#34;output&#34;] = &#34;output&#34;;
        

        self.system_dict[&#34;params&#34;][&#34;fourcc&#34;] = &#34;mp4v&#34;;
        self.system_dict[&#34;params&#34;][&#34;half&#34;] = False;
        self.system_dict[&#34;params&#34;][&#34;device&#34;] = &#34;0&#34;;
        self.system_dict[&#34;params&#34;][&#34;agnostic_nms&#34;] = False;
        self.system_dict[&#34;params&#34;][&#34;classes&#34;] = &#34;&#34;;
        self.system_dict[&#34;params&#34;][&#34;device&#34;] = &#34;0&#34;;
        
        self.system_dict[&#34;params&#34;][&#34;view_img&#34;] = False;
        self.system_dict[&#34;params&#34;][&#34;save_txt&#34;] = True;
        self.system_dict[&#34;params&#34;][&#34;save_img&#34;] = True;

        self.system_dict[&#34;params&#34;][&#34;cfg&#34;] = &#34;custom_data/ship/yolov3.cfg&#34;;
        self.system_dict[&#34;params&#34;][&#34;names&#34;] = &#34;custom_data/ship/classes_list.txt&#34;;
        self.system_dict[&#34;params&#34;][&#34;weights&#34;] = &#34;weights/last.pt&#34;;

        self.system_dict[&#34;params&#34;][&#34;img_size&#34;] = 416;
        self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;] = 0.3;
        self.system_dict[&#34;params&#34;][&#34;iou_thres&#34;] = 0.5;


    def Model(self, model_name, class_list, weight, use_gpu=True, input_size=416, half_precision=False):
        &#39;&#39;&#39;
        User function: Set Model parameters

            Available Models
                yolov3
                yolov3s
                yolov3-spp
                yolov3-spp3
                yolov3-tiny
                yolov3-spp-matrix
                csresnext50-panet-spp


        Args:
            model_name (str): Select model from available models
            class_list (list): List of classes as per given in training session
            weight (srt): Path to file storing model weights 
            use_gpu (bool): If True, model is loaded onto GPU device, else on CPU
            half_precision (bool): If True, uses only 16 bit floating point operations for faster inferencing

        Returns:
            None
        &#39;&#39;&#39;
        self.system_dict[&#34;params&#34;][&#34;cfg&#34;] = model_name + &#34;.cfg&#34;; 
        self.system_dict[&#34;params&#34;][&#34;half&#34;] = half_precision;
        self.system_dict[&#34;params&#34;][&#34;names&#34;] = class_list;
        self.system_dict[&#34;params&#34;][&#34;weights&#34;] = weight;
        self.system_dict[&#34;params&#34;][&#34;use_gpu&#34;] = use_gpu;
        self.system_dict[&#34;params&#34;][&#34;img_size&#34;] = input_size;

        self.system_dict[&#34;local&#34;][&#34;device&#34;] = torch_utils.select_device(device=self.system_dict[&#34;params&#34;][&#34;device&#34;] if use_gpu else &#39;cpu&#39;);

        self.system_dict[&#34;local&#34;][&#34;model&#34;] = Darknet(self.system_dict[&#34;params&#34;][&#34;cfg&#34;], 
                                                    self.system_dict[&#34;params&#34;][&#34;img_size&#34;]);

        # Load weights
        attempt_download(self.system_dict[&#34;params&#34;][&#34;weights&#34;])
        if self.system_dict[&#34;params&#34;][&#34;weights&#34;].endswith(&#39;.pt&#39;):  # pytorch format
            self.system_dict[&#34;local&#34;][&#34;model&#34;].load_state_dict(torch.load(self.system_dict[&#34;params&#34;][&#34;weights&#34;], 
                                                                            map_location=self.system_dict[&#34;local&#34;][&#34;device&#34;])[&#39;model&#39;])
        else:  # darknet format
            load_darknet_weights(self.system_dict[&#34;local&#34;][&#34;model&#34;], 
                                    self.system_dict[&#34;params&#34;][&#34;weights&#34;])

        # Second-stage classifier
        self.system_dict[&#34;params&#34;][&#34;classify&#34;] = False
        if self.system_dict[&#34;params&#34;][&#34;classify&#34;]:
            modelc = torch_utils.load_classifier(name=&#39;resnet101&#39;, n=2)  # initialize
            modelc.load_state_dict(torch.load(&#39;weights/resnet101.pt&#39;, map_location=device)[&#39;model&#39;])  # load weights
            modelc.to(device).eval()

        self.system_dict[&#34;local&#34;][&#34;model&#34;].to(self.system_dict[&#34;local&#34;][&#34;device&#34;]).eval()

        # Half precision
        self.system_dict[&#34;params&#34;][&#34;half&#34;] = self.system_dict[&#34;params&#34;][&#34;half&#34;] and self.system_dict[&#34;local&#34;][&#34;device&#34;].type != &#39;cpu&#39;  # half precision only supported on CUDA
        if self.system_dict[&#34;params&#34;][&#34;half&#34;]:
            self.system_dict[&#34;local&#34;][&#34;model&#34;].half()



    def Predict(self, img_path, conf_thres=0.3, iou_thres=0.5):
        &#39;&#39;&#39;
        User function: Run inference on image and visualize it

        Args:
            img_path (str): Relative path to the image file
            conf_thres (float): Threshold for predicted scores. Scores for objects detected below this score will not be displayed 
            iou_thres (float): Threshold for bounding boxes nms merging

        Returns:
            None.
        &#39;&#39;&#39;
        self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;] = conf_thres;
        self.system_dict[&#34;params&#34;][&#34;iou_thres&#34;] = iou_thres;
        view_img = self.system_dict[&#34;params&#34;][&#34;view_img&#34;];
        save_txt = self.system_dict[&#34;params&#34;][&#34;save_txt&#34;];
        save_img = self.system_dict[&#34;params&#34;][&#34;save_img&#34;];
        out = self.system_dict[&#34;params&#34;][&#34;output&#34;];
        source = &#34;tmp&#34;;

        if(not os.path.isdir(source)):
            os.mkdir(source);
        else:
            os.system(&#34;rm -r &#34; + source);
            os.mkdir(source);

        if(not os.path.isdir(out)):
            os.mkdir(out);
        else:
            os.system(&#34;rm -r &#34; + out);
            os.mkdir(out);

        os.system(&#34;cp &#34; + img_path + &#34; &#34; + source + &#34;/&#34;);

        self.system_dict[&#34;local&#34;][&#34;dataset&#34;] = LoadImages(source, 
                                                            img_size=self.system_dict[&#34;params&#34;][&#34;img_size&#34;], 
                                                            half=self.system_dict[&#34;params&#34;][&#34;half&#34;]);

        # Get names and colors
        names = self.system_dict[&#34;params&#34;][&#34;names&#34;]
        colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]


        # Run inference
        t0 = time.time()
        for path, img, im0s, vid_cap in self.system_dict[&#34;local&#34;][&#34;dataset&#34;]:
            t = time.time()

            # Get detections
            img = torch.from_numpy(img).to(self.system_dict[&#34;local&#34;][&#34;device&#34;])
            if img.ndimension() == 3:
                img = img.unsqueeze(0)
            pred = self.system_dict[&#34;local&#34;][&#34;model&#34;](img)[0]
            

            if self.system_dict[&#34;params&#34;][&#34;half&#34;]:
                pred = pred.float()

            # Apply NMS
            pred = non_max_suppression(pred, self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;], 
                                       self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;], 
                                       classes=self.system_dict[&#34;params&#34;][&#34;classes&#34;], 
                                       agnostic=self.system_dict[&#34;params&#34;][&#34;agnostic_nms&#34;])
            

            # Apply Classifier
            if self.system_dict[&#34;params&#34;][&#34;classify&#34;]:
                pred = apply_classifier(pred, modelc, img, im0s)

            # Process detections
            for i, det in enumerate(pred):  # detections per image
                p, s, im0 = path, &#39;&#39;, im0s

                save_path = str(Path(out) / Path(p).name)
                s += &#39;%gx%g &#39; % img.shape[2:]  # print string
                if det is not None and len(det):
                    # Rescale boxes from img_size to im0 size
                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                    # Print results
                    for c in det[:, -1].unique():
                        n = (det[:, -1] == c).sum()  # detections per class
                        s += &#39;%g %ss, &#39; % (n, names[int(c)])  # add to string

                    # Write results
                    for *xyxy, conf, cls in det:
                        if save_txt:  # Write to file
                            with open(save_path + &#39;.txt&#39;, &#39;a&#39;) as file:
                                file.write((&#39;%g &#39; * 6 + &#39;\n&#39;) % (*xyxy, cls, conf))

                        if save_img or view_img:  # Add bbox to image
                            label = &#39;%s %.2f&#39; % (names[int(cls)], conf)
                            plot_one_box(xyxy, im0, label=label, color=colors[int(cls)])

                # Print time (inference + NMS)
                print(&#39;%sDone. (%.3fs)&#39; % (s, time.time() - t))

                # Stream results
                if view_img:
                    cv2.imshow(p, im0)
                    if cv2.waitKey(1) == ord(&#39;q&#39;):  # q to quit
                        raise StopIteration

                # Save results (image with detections)
                if save_img:
                    if self.system_dict[&#34;local&#34;][&#34;dataset&#34;].mode == &#39;images&#39;:
                        cv2.imwrite(save_path, im0)
                        cv2.imwrite(&#34;output.jpg&#34;, im0);


        if save_txt or save_img:
            print(&#39;Results saved to %s&#39; % os.getcwd() + os.sep + out)
            if platform == &#39;darwin&#39;:  # MacOS
                os.system(&#39;open &#39; + out + &#39; &#39; + save_path)

        print(&#39;Done. (%.3fs)&#39; % (time.time() - t0))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="7_yolov3.lib.infer_detector.Infer"><code class="flex name class">
<span>class <span class="ident">Infer</span></span>
<span>(</span><span>verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for main inference</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>Set verbosity levels
0 - Print Nothing
1 - Print desired details</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Infer():
    &#39;&#39;&#39;
    Class for main inference

    Args:
        verbose (int): Set verbosity levels
                        0 - Print Nothing
                        1 - Print desired details
    &#39;&#39;&#39;
    def __init__(self, verbose=1):
        self.system_dict = {};
        self.system_dict[&#34;verbose&#34;] = verbose;
        self.system_dict[&#34;local&#34;] = {};


        self.system_dict[&#34;params&#34;] = {};
        self.system_dict[&#34;params&#34;][&#34;output&#34;] = &#34;output&#34;;
        

        self.system_dict[&#34;params&#34;][&#34;fourcc&#34;] = &#34;mp4v&#34;;
        self.system_dict[&#34;params&#34;][&#34;half&#34;] = False;
        self.system_dict[&#34;params&#34;][&#34;device&#34;] = &#34;0&#34;;
        self.system_dict[&#34;params&#34;][&#34;agnostic_nms&#34;] = False;
        self.system_dict[&#34;params&#34;][&#34;classes&#34;] = &#34;&#34;;
        self.system_dict[&#34;params&#34;][&#34;device&#34;] = &#34;0&#34;;
        
        self.system_dict[&#34;params&#34;][&#34;view_img&#34;] = False;
        self.system_dict[&#34;params&#34;][&#34;save_txt&#34;] = True;
        self.system_dict[&#34;params&#34;][&#34;save_img&#34;] = True;

        self.system_dict[&#34;params&#34;][&#34;cfg&#34;] = &#34;custom_data/ship/yolov3.cfg&#34;;
        self.system_dict[&#34;params&#34;][&#34;names&#34;] = &#34;custom_data/ship/classes_list.txt&#34;;
        self.system_dict[&#34;params&#34;][&#34;weights&#34;] = &#34;weights/last.pt&#34;;

        self.system_dict[&#34;params&#34;][&#34;img_size&#34;] = 416;
        self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;] = 0.3;
        self.system_dict[&#34;params&#34;][&#34;iou_thres&#34;] = 0.5;


    def Model(self, model_name, class_list, weight, use_gpu=True, input_size=416, half_precision=False):
        &#39;&#39;&#39;
        User function: Set Model parameters

            Available Models
                yolov3
                yolov3s
                yolov3-spp
                yolov3-spp3
                yolov3-tiny
                yolov3-spp-matrix
                csresnext50-panet-spp


        Args:
            model_name (str): Select model from available models
            class_list (list): List of classes as per given in training session
            weight (srt): Path to file storing model weights 
            use_gpu (bool): If True, model is loaded onto GPU device, else on CPU
            half_precision (bool): If True, uses only 16 bit floating point operations for faster inferencing

        Returns:
            None
        &#39;&#39;&#39;
        self.system_dict[&#34;params&#34;][&#34;cfg&#34;] = model_name + &#34;.cfg&#34;; 
        self.system_dict[&#34;params&#34;][&#34;half&#34;] = half_precision;
        self.system_dict[&#34;params&#34;][&#34;names&#34;] = class_list;
        self.system_dict[&#34;params&#34;][&#34;weights&#34;] = weight;
        self.system_dict[&#34;params&#34;][&#34;use_gpu&#34;] = use_gpu;
        self.system_dict[&#34;params&#34;][&#34;img_size&#34;] = input_size;

        self.system_dict[&#34;local&#34;][&#34;device&#34;] = torch_utils.select_device(device=self.system_dict[&#34;params&#34;][&#34;device&#34;] if use_gpu else &#39;cpu&#39;);

        self.system_dict[&#34;local&#34;][&#34;model&#34;] = Darknet(self.system_dict[&#34;params&#34;][&#34;cfg&#34;], 
                                                    self.system_dict[&#34;params&#34;][&#34;img_size&#34;]);

        # Load weights
        attempt_download(self.system_dict[&#34;params&#34;][&#34;weights&#34;])
        if self.system_dict[&#34;params&#34;][&#34;weights&#34;].endswith(&#39;.pt&#39;):  # pytorch format
            self.system_dict[&#34;local&#34;][&#34;model&#34;].load_state_dict(torch.load(self.system_dict[&#34;params&#34;][&#34;weights&#34;], 
                                                                            map_location=self.system_dict[&#34;local&#34;][&#34;device&#34;])[&#39;model&#39;])
        else:  # darknet format
            load_darknet_weights(self.system_dict[&#34;local&#34;][&#34;model&#34;], 
                                    self.system_dict[&#34;params&#34;][&#34;weights&#34;])

        # Second-stage classifier
        self.system_dict[&#34;params&#34;][&#34;classify&#34;] = False
        if self.system_dict[&#34;params&#34;][&#34;classify&#34;]:
            modelc = torch_utils.load_classifier(name=&#39;resnet101&#39;, n=2)  # initialize
            modelc.load_state_dict(torch.load(&#39;weights/resnet101.pt&#39;, map_location=device)[&#39;model&#39;])  # load weights
            modelc.to(device).eval()

        self.system_dict[&#34;local&#34;][&#34;model&#34;].to(self.system_dict[&#34;local&#34;][&#34;device&#34;]).eval()

        # Half precision
        self.system_dict[&#34;params&#34;][&#34;half&#34;] = self.system_dict[&#34;params&#34;][&#34;half&#34;] and self.system_dict[&#34;local&#34;][&#34;device&#34;].type != &#39;cpu&#39;  # half precision only supported on CUDA
        if self.system_dict[&#34;params&#34;][&#34;half&#34;]:
            self.system_dict[&#34;local&#34;][&#34;model&#34;].half()



    def Predict(self, img_path, conf_thres=0.3, iou_thres=0.5):
        &#39;&#39;&#39;
        User function: Run inference on image and visualize it

        Args:
            img_path (str): Relative path to the image file
            conf_thres (float): Threshold for predicted scores. Scores for objects detected below this score will not be displayed 
            iou_thres (float): Threshold for bounding boxes nms merging

        Returns:
            None.
        &#39;&#39;&#39;
        self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;] = conf_thres;
        self.system_dict[&#34;params&#34;][&#34;iou_thres&#34;] = iou_thres;
        view_img = self.system_dict[&#34;params&#34;][&#34;view_img&#34;];
        save_txt = self.system_dict[&#34;params&#34;][&#34;save_txt&#34;];
        save_img = self.system_dict[&#34;params&#34;][&#34;save_img&#34;];
        out = self.system_dict[&#34;params&#34;][&#34;output&#34;];
        source = &#34;tmp&#34;;

        if(not os.path.isdir(source)):
            os.mkdir(source);
        else:
            os.system(&#34;rm -r &#34; + source);
            os.mkdir(source);

        if(not os.path.isdir(out)):
            os.mkdir(out);
        else:
            os.system(&#34;rm -r &#34; + out);
            os.mkdir(out);

        os.system(&#34;cp &#34; + img_path + &#34; &#34; + source + &#34;/&#34;);

        self.system_dict[&#34;local&#34;][&#34;dataset&#34;] = LoadImages(source, 
                                                            img_size=self.system_dict[&#34;params&#34;][&#34;img_size&#34;], 
                                                            half=self.system_dict[&#34;params&#34;][&#34;half&#34;]);

        # Get names and colors
        names = self.system_dict[&#34;params&#34;][&#34;names&#34;]
        colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]


        # Run inference
        t0 = time.time()
        for path, img, im0s, vid_cap in self.system_dict[&#34;local&#34;][&#34;dataset&#34;]:
            t = time.time()

            # Get detections
            img = torch.from_numpy(img).to(self.system_dict[&#34;local&#34;][&#34;device&#34;])
            if img.ndimension() == 3:
                img = img.unsqueeze(0)
            pred = self.system_dict[&#34;local&#34;][&#34;model&#34;](img)[0]
            

            if self.system_dict[&#34;params&#34;][&#34;half&#34;]:
                pred = pred.float()

            # Apply NMS
            pred = non_max_suppression(pred, self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;], 
                                       self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;], 
                                       classes=self.system_dict[&#34;params&#34;][&#34;classes&#34;], 
                                       agnostic=self.system_dict[&#34;params&#34;][&#34;agnostic_nms&#34;])
            

            # Apply Classifier
            if self.system_dict[&#34;params&#34;][&#34;classify&#34;]:
                pred = apply_classifier(pred, modelc, img, im0s)

            # Process detections
            for i, det in enumerate(pred):  # detections per image
                p, s, im0 = path, &#39;&#39;, im0s

                save_path = str(Path(out) / Path(p).name)
                s += &#39;%gx%g &#39; % img.shape[2:]  # print string
                if det is not None and len(det):
                    # Rescale boxes from img_size to im0 size
                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                    # Print results
                    for c in det[:, -1].unique():
                        n = (det[:, -1] == c).sum()  # detections per class
                        s += &#39;%g %ss, &#39; % (n, names[int(c)])  # add to string

                    # Write results
                    for *xyxy, conf, cls in det:
                        if save_txt:  # Write to file
                            with open(save_path + &#39;.txt&#39;, &#39;a&#39;) as file:
                                file.write((&#39;%g &#39; * 6 + &#39;\n&#39;) % (*xyxy, cls, conf))

                        if save_img or view_img:  # Add bbox to image
                            label = &#39;%s %.2f&#39; % (names[int(cls)], conf)
                            plot_one_box(xyxy, im0, label=label, color=colors[int(cls)])

                # Print time (inference + NMS)
                print(&#39;%sDone. (%.3fs)&#39; % (s, time.time() - t))

                # Stream results
                if view_img:
                    cv2.imshow(p, im0)
                    if cv2.waitKey(1) == ord(&#39;q&#39;):  # q to quit
                        raise StopIteration

                # Save results (image with detections)
                if save_img:
                    if self.system_dict[&#34;local&#34;][&#34;dataset&#34;].mode == &#39;images&#39;:
                        cv2.imwrite(save_path, im0)
                        cv2.imwrite(&#34;output.jpg&#34;, im0);


        if save_txt or save_img:
            print(&#39;Results saved to %s&#39; % os.getcwd() + os.sep + out)
            if platform == &#39;darwin&#39;:  # MacOS
                os.system(&#39;open &#39; + out + &#39; &#39; + save_path)

        print(&#39;Done. (%.3fs)&#39; % (time.time() - t0))</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="7_yolov3.lib.infer_detector.Infer.Model"><code class="name flex">
<span>def <span class="ident">Model</span></span>(<span>self, model_name, class_list, weight, use_gpu=True, input_size=416, half_precision=False)</span>
</code></dt>
<dd>
<div class="desc"><p>User function: Set Model parameters</p>
<pre><code>Available Models
    yolov3
    yolov3s
    yolov3-spp
    yolov3-spp3
    yolov3-tiny
    yolov3-spp-matrix
    csresnext50-panet-spp
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Select model from available models</dd>
<dt><strong><code>class_list</code></strong> :&ensp;<code>list</code></dt>
<dd>List of classes as per given in training session</dd>
<dt><strong><code>weight</code></strong> :&ensp;<code>srt</code></dt>
<dd>Path to file storing model weights </dd>
<dt><strong><code>use_gpu</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, model is loaded onto GPU device, else on CPU</dd>
<dt><strong><code>half_precision</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, uses only 16 bit floating point operations for faster inferencing</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Model(self, model_name, class_list, weight, use_gpu=True, input_size=416, half_precision=False):
    &#39;&#39;&#39;
    User function: Set Model parameters

        Available Models
            yolov3
            yolov3s
            yolov3-spp
            yolov3-spp3
            yolov3-tiny
            yolov3-spp-matrix
            csresnext50-panet-spp


    Args:
        model_name (str): Select model from available models
        class_list (list): List of classes as per given in training session
        weight (srt): Path to file storing model weights 
        use_gpu (bool): If True, model is loaded onto GPU device, else on CPU
        half_precision (bool): If True, uses only 16 bit floating point operations for faster inferencing

    Returns:
        None
    &#39;&#39;&#39;
    self.system_dict[&#34;params&#34;][&#34;cfg&#34;] = model_name + &#34;.cfg&#34;; 
    self.system_dict[&#34;params&#34;][&#34;half&#34;] = half_precision;
    self.system_dict[&#34;params&#34;][&#34;names&#34;] = class_list;
    self.system_dict[&#34;params&#34;][&#34;weights&#34;] = weight;
    self.system_dict[&#34;params&#34;][&#34;use_gpu&#34;] = use_gpu;
    self.system_dict[&#34;params&#34;][&#34;img_size&#34;] = input_size;

    self.system_dict[&#34;local&#34;][&#34;device&#34;] = torch_utils.select_device(device=self.system_dict[&#34;params&#34;][&#34;device&#34;] if use_gpu else &#39;cpu&#39;);

    self.system_dict[&#34;local&#34;][&#34;model&#34;] = Darknet(self.system_dict[&#34;params&#34;][&#34;cfg&#34;], 
                                                self.system_dict[&#34;params&#34;][&#34;img_size&#34;]);

    # Load weights
    attempt_download(self.system_dict[&#34;params&#34;][&#34;weights&#34;])
    if self.system_dict[&#34;params&#34;][&#34;weights&#34;].endswith(&#39;.pt&#39;):  # pytorch format
        self.system_dict[&#34;local&#34;][&#34;model&#34;].load_state_dict(torch.load(self.system_dict[&#34;params&#34;][&#34;weights&#34;], 
                                                                        map_location=self.system_dict[&#34;local&#34;][&#34;device&#34;])[&#39;model&#39;])
    else:  # darknet format
        load_darknet_weights(self.system_dict[&#34;local&#34;][&#34;model&#34;], 
                                self.system_dict[&#34;params&#34;][&#34;weights&#34;])

    # Second-stage classifier
    self.system_dict[&#34;params&#34;][&#34;classify&#34;] = False
    if self.system_dict[&#34;params&#34;][&#34;classify&#34;]:
        modelc = torch_utils.load_classifier(name=&#39;resnet101&#39;, n=2)  # initialize
        modelc.load_state_dict(torch.load(&#39;weights/resnet101.pt&#39;, map_location=device)[&#39;model&#39;])  # load weights
        modelc.to(device).eval()

    self.system_dict[&#34;local&#34;][&#34;model&#34;].to(self.system_dict[&#34;local&#34;][&#34;device&#34;]).eval()

    # Half precision
    self.system_dict[&#34;params&#34;][&#34;half&#34;] = self.system_dict[&#34;params&#34;][&#34;half&#34;] and self.system_dict[&#34;local&#34;][&#34;device&#34;].type != &#39;cpu&#39;  # half precision only supported on CUDA
    if self.system_dict[&#34;params&#34;][&#34;half&#34;]:
        self.system_dict[&#34;local&#34;][&#34;model&#34;].half()</code></pre>
</details>
</dd>
<dt id="7_yolov3.lib.infer_detector.Infer.Predict"><code class="name flex">
<span>def <span class="ident">Predict</span></span>(<span>self, img_path, conf_thres=0.3, iou_thres=0.5)</span>
</code></dt>
<dd>
<div class="desc"><p>User function: Run inference on image and visualize it</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>img_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Relative path to the image file</dd>
<dt><strong><code>conf_thres</code></strong> :&ensp;<code>float</code></dt>
<dd>Threshold for predicted scores. Scores for objects detected below this score will not be displayed </dd>
<dt><strong><code>iou_thres</code></strong> :&ensp;<code>float</code></dt>
<dd>Threshold for bounding boxes nms merging</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Predict(self, img_path, conf_thres=0.3, iou_thres=0.5):
    &#39;&#39;&#39;
    User function: Run inference on image and visualize it

    Args:
        img_path (str): Relative path to the image file
        conf_thres (float): Threshold for predicted scores. Scores for objects detected below this score will not be displayed 
        iou_thres (float): Threshold for bounding boxes nms merging

    Returns:
        None.
    &#39;&#39;&#39;
    self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;] = conf_thres;
    self.system_dict[&#34;params&#34;][&#34;iou_thres&#34;] = iou_thres;
    view_img = self.system_dict[&#34;params&#34;][&#34;view_img&#34;];
    save_txt = self.system_dict[&#34;params&#34;][&#34;save_txt&#34;];
    save_img = self.system_dict[&#34;params&#34;][&#34;save_img&#34;];
    out = self.system_dict[&#34;params&#34;][&#34;output&#34;];
    source = &#34;tmp&#34;;

    if(not os.path.isdir(source)):
        os.mkdir(source);
    else:
        os.system(&#34;rm -r &#34; + source);
        os.mkdir(source);

    if(not os.path.isdir(out)):
        os.mkdir(out);
    else:
        os.system(&#34;rm -r &#34; + out);
        os.mkdir(out);

    os.system(&#34;cp &#34; + img_path + &#34; &#34; + source + &#34;/&#34;);

    self.system_dict[&#34;local&#34;][&#34;dataset&#34;] = LoadImages(source, 
                                                        img_size=self.system_dict[&#34;params&#34;][&#34;img_size&#34;], 
                                                        half=self.system_dict[&#34;params&#34;][&#34;half&#34;]);

    # Get names and colors
    names = self.system_dict[&#34;params&#34;][&#34;names&#34;]
    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]


    # Run inference
    t0 = time.time()
    for path, img, im0s, vid_cap in self.system_dict[&#34;local&#34;][&#34;dataset&#34;]:
        t = time.time()

        # Get detections
        img = torch.from_numpy(img).to(self.system_dict[&#34;local&#34;][&#34;device&#34;])
        if img.ndimension() == 3:
            img = img.unsqueeze(0)
        pred = self.system_dict[&#34;local&#34;][&#34;model&#34;](img)[0]
        

        if self.system_dict[&#34;params&#34;][&#34;half&#34;]:
            pred = pred.float()

        # Apply NMS
        pred = non_max_suppression(pred, self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;], 
                                   self.system_dict[&#34;params&#34;][&#34;conf_thres&#34;], 
                                   classes=self.system_dict[&#34;params&#34;][&#34;classes&#34;], 
                                   agnostic=self.system_dict[&#34;params&#34;][&#34;agnostic_nms&#34;])
        

        # Apply Classifier
        if self.system_dict[&#34;params&#34;][&#34;classify&#34;]:
            pred = apply_classifier(pred, modelc, img, im0s)

        # Process detections
        for i, det in enumerate(pred):  # detections per image
            p, s, im0 = path, &#39;&#39;, im0s

            save_path = str(Path(out) / Path(p).name)
            s += &#39;%gx%g &#39; % img.shape[2:]  # print string
            if det is not None and len(det):
                # Rescale boxes from img_size to im0 size
                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                # Print results
                for c in det[:, -1].unique():
                    n = (det[:, -1] == c).sum()  # detections per class
                    s += &#39;%g %ss, &#39; % (n, names[int(c)])  # add to string

                # Write results
                for *xyxy, conf, cls in det:
                    if save_txt:  # Write to file
                        with open(save_path + &#39;.txt&#39;, &#39;a&#39;) as file:
                            file.write((&#39;%g &#39; * 6 + &#39;\n&#39;) % (*xyxy, cls, conf))

                    if save_img or view_img:  # Add bbox to image
                        label = &#39;%s %.2f&#39; % (names[int(cls)], conf)
                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)])

            # Print time (inference + NMS)
            print(&#39;%sDone. (%.3fs)&#39; % (s, time.time() - t))

            # Stream results
            if view_img:
                cv2.imshow(p, im0)
                if cv2.waitKey(1) == ord(&#39;q&#39;):  # q to quit
                    raise StopIteration

            # Save results (image with detections)
            if save_img:
                if self.system_dict[&#34;local&#34;][&#34;dataset&#34;].mode == &#39;images&#39;:
                    cv2.imwrite(save_path, im0)
                    cv2.imwrite(&#34;output.jpg&#34;, im0);


    if save_txt or save_img:
        print(&#39;Results saved to %s&#39; % os.getcwd() + os.sep + out)
        if platform == &#39;darwin&#39;:  # MacOS
            os.system(&#39;open &#39; + out + &#39; &#39; + save_path)

    print(&#39;Done. (%.3fs)&#39; % (time.time() - t0))</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="7_yolov3.lib" href="index.html">7_yolov3.lib</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="7_yolov3.lib.infer_detector.Infer" href="#7_yolov3.lib.infer_detector.Infer">Infer</a></code></h4>
<ul class="">
<li><code><a title="7_yolov3.lib.infer_detector.Infer.Model" href="#7_yolov3.lib.infer_detector.Infer.Model">Model</a></code></li>
<li><code><a title="7_yolov3.lib.infer_detector.Infer.Predict" href="#7_yolov3.lib.infer_detector.Infer.Predict">Predict</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>